{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cai_target_transform_hybrid.py\n",
    "# Hybrid clustering target transformation for CAI_farm:\n",
    "# Ward HAC (k=2) -> seeds KMeans (k=2) + silhouette + bootstrap stability + plots\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# ------------------------------- Config --------------------------------\n",
    "INPUT = \"data/processed/normalised_with_cai.csv\"  # must contain column 'CAI_farm'\n",
    "CAI_COL = \"CAI_farm\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "B_BOOT = 500                   # bootstrap iterations for stability\n",
    "KM_MAX_ITER = 500\n",
    "KM_TOL = 1e-4\n",
    "\n",
    "# Visualization params\n",
    "DENDRO_SUBSAMPLE = 1200        # using a subset to draw dendrogram (scales well)\n",
    "CUT_HEIGHT = 1.0               # dashed line on dendrogram (illustrative)\n",
    "HIST_BINS = 80\n",
    "\n",
    "OUTDIR = Path(\"data/processed/\")\n",
    "OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# --------------------------- Helper functions --------------------------\n",
    "def ensure_binary_high_is_one(labels: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map 2 cluster labels to {0,1} so that label 1 corresponds to the HIGH-CAI cluster.\n",
    "    \"\"\"\n",
    "    labels = labels.astype(int)\n",
    "    means = [X[labels == k].mean() if np.any(labels == k) else -np.inf for k in np.unique(labels)]\n",
    "    # If cluster '1' is not the higher-mean cluster, flip labels\n",
    "    uniq = np.unique(labels)\n",
    "    if len(uniq) != 2:\n",
    "        raise ValueError(\"Expected exactly 2 clusters.\")\n",
    "    # Identify which label has higher mean\n",
    "    high_label = uniq[np.argmax([means[0] if uniq[0]==0 else means[1],\n",
    "                                 means[1] if uniq[1]==1 else means[0]])]\n",
    "    # Recode: high -> 1, other -> 0\n",
    "    new = np.where(labels == high_label, 1, 0)\n",
    "    return new\n",
    "\n",
    "def fit_hac_get_centers(X: np.ndarray, random_state: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fit Ward hierarchical (k=2) on all data using sklearn's AgglomerativeClustering and\n",
    "    return (labels_01, centers_2x1) where centers are ordered ascending by value.\n",
    "    \"\"\"\n",
    "    hac = AgglomerativeClustering(n_clusters=2, linkage=\"ward\", affinity=\"euclidean\")\n",
    "    hac_labels = hac.fit_predict(X)\n",
    "    # Map to 0/1 with 1 being 'high'\n",
    "    labels01 = ensure_binary_high_is_one(hac_labels, X.ravel())\n",
    "    # Compute centers (means) by cluster\n",
    "    c0 = X[labels01 == 0].mean()\n",
    "    c1 = X[labels01 == 1].mean()\n",
    "    centers = np.array([[min(c0, c1)], [max(c0, c1)]], dtype=float)\n",
    "    return labels01, centers\n",
    "\n",
    "def fit_kmeans_with_init(X: np.ndarray, init_centers: np.ndarray, random_state: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fit KMeans(k=2) with provided initial centers (2x1), return (labels01, centers_sorted).\n",
    "    \"\"\"\n",
    "    km = KMeans(\n",
    "        n_clusters=2,\n",
    "        init=init_centers,\n",
    "        n_init=1,                 # use provided init exactly\n",
    "        max_iter=KM_MAX_ITER,\n",
    "        tol=KM_TOL,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    km.fit(X)\n",
    "    labels = km.labels_.copy()\n",
    "    # Order centers and ensure label '1' is the higher-mean cluster\n",
    "    centers = km.cluster_centers_.reshape(-1)\n",
    "    order = np.argsort(centers)\n",
    "    centers_sorted = centers[order]\n",
    "    # Remap labels to match sorted centers (low->0, high->1)\n",
    "    labels_sorted = np.zeros_like(labels)\n",
    "    labels_sorted[labels == order[1]] = 1\n",
    "    labels_sorted[labels == order[0]] = 0\n",
    "    return labels_sorted, centers_sorted.reshape(-1, 1)\n",
    "\n",
    "def silhouettes(X: np.ndarray, labels01: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute mean and median silhouette scores for 2 clusters on 1D data.\n",
    "    \"\"\"\n",
    "    if len(np.unique(labels01)) < 2:\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "    sil = silhouette_samples(X, labels01, metric=\"euclidean\")\n",
    "    return float(np.nanmean(sil)), float(np.nanmedian(sil))\n",
    "\n",
    "def bootstrap_stability(\n",
    "    X: np.ndarray,\n",
    "    labels_ref: np.ndarray,\n",
    "    random_state: int,\n",
    "    B: int = 500\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bootstrap stability:\n",
    "      - For each bootstrap sample, fit HAC (k=2) -> get centers -> fit KMeans with those centers\n",
    "      - Predict ALL X using those centroids (via km.predict)\n",
    "      - Compare to reference labels (from the full-data KMeans) and average matches\n",
    "    Returns: stability score per observation (n,)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n = X.shape[0]\n",
    "    matches = np.zeros(n, dtype=float)\n",
    "\n",
    "    for b in range(B):\n",
    "        idx = rng.randint(0, n, size=n)  # bootstrap indices\n",
    "        Xb = X[idx]\n",
    "        # HAC on bootstrap to seed KMeans\n",
    "        _, centers_b = fit_hac_get_centers(Xb, random_state + b + 1)\n",
    "        km_b = KMeans(n_clusters=2, init=centers_b, n_init=1, max_iter=KM_MAX_ITER,\n",
    "                      tol=KM_TOL, random_state=random_state + b + 1)\n",
    "        km_b.fit(Xb)\n",
    "        # Predict all original points using bootstrap-trained kmeans\n",
    "        pred_b = km_b.predict(X)\n",
    "        # Align such that 1==HIGH cluster\n",
    "        centers_b_full = km_b.cluster_centers_.reshape(-1)\n",
    "        order = np.argsort(centers_b_full)\n",
    "        pred_b_aligned = np.zeros_like(pred_b)\n",
    "        pred_b_aligned[pred_b == order[1]] = 1\n",
    "        pred_b_aligned[pred_b == order[0]] = 0\n",
    "        matches += (pred_b_aligned == labels_ref).astype(float)\n",
    "\n",
    "    return matches / B\n",
    "\n",
    "# --------------------------------- Main --------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load data with CAI_farm\n",
    "    df = pd.read_csv(INPUT)\n",
    "    if CAI_COL not in df.columns:\n",
    "        raise KeyError(f\"Column '{CAI_COL}' not found in {INPUT}\")\n",
    "\n",
    "    X = df[CAI_COL].astype(float).values.reshape(-1, 1)\n",
    "    n = X.shape[0]\n",
    "    print(f\"Loaded {n:,} rows with CAI column: {CAI_COL}\")\n",
    "\n",
    "    # 2) Ward HAC (k=2) on full data -> labels + centers\n",
    "    hac_labels01, hac_centers = fit_hac_get_centers(X, RANDOM_SEED)\n",
    "    sil_hac_mean, sil_hac_median = silhouettes(X, hac_labels01)\n",
    "    print(f\"Ward HAC (k=2) Silhouette: mean={sil_hac_mean:.3f}, median={sil_hac_median:.3f}\")\n",
    "\n",
    "    # 3) KMeans (k=2) seeded by HAC centers\n",
    "    km_labels01, km_centers = fit_kmeans_with_init(X, hac_centers, RANDOM_SEED)\n",
    "    sil_km_mean, sil_km_median = silhouettes(X, km_labels01)\n",
    "    print(f\"KMeans (k=2, HAC-seeded) Silhouette: mean={sil_km_mean:.3f}, median={sil_km_median:.3f}\")\n",
    "\n",
    "    # 4) Bootstrap stability\n",
    "    print(f\"Bootstrapping stability with B={B_BOOT} ...\")\n",
    "    stability = bootstrap_stability(X, km_labels01, RANDOM_SEED, B=B_BOOT)\n",
    "    print(f\"Stability: median={np.median(stability):.3f}, mean={np.mean(stability):.3f}\")\n",
    "\n",
    "    # 5) Silhouette table\n",
    "    sil_table = pd.DataFrame([\n",
    "        {\"Method\": \"K-means (k=2)\", \"Silhouette (mean)\": round(sil_km_mean, 3),\n",
    "         \"Silhouette (median)\": round(sil_km_median, 3), \"n\": n},\n",
    "        {\"Method\": \"Hierarchical/Ward (k=2)\", \"Silhouette (mean)\": round(sil_hac_mean, 3),\n",
    "         \"Silhouette (median)\": round(sil_hac_median, 3), \"n\": n},\n",
    "    ])\n",
    "    sil_table.to_csv(OUTDIR / \"silhouette_summary.csv\", index=False)\n",
    "\n",
    "    # 6) Attach cluster outputs to dataframe\n",
    "    # Ensure 0 = Low, 1 = High (already enforced), add names & centroids\n",
    "    centroid_low, centroid_high = float(km_centers[0, 0]), float(km_centers[1, 0])\n",
    "    df[\"binary_chai\"] = km_labels01\n",
    "    df[\"cluster_name\"] = np.where(df[\"binary_cai\"] == 1, \"High\", \"Low\")\n",
    "    df[\"stability_score\"] = stability\n",
    "    df[\"centroid_low\"] = centroid_low\n",
    "    df[\"centroid_high\"] = centroid_high\n",
    "\n",
    "    df.to_csv(OUTDIR / \"normalised_with_binary_cai.csv\", index=False)\n",
    "\n",
    "    # 7) Dendrogram plot (on a representative subsample for readability)\n",
    "    n_sub = min(DENDRO_SUBSAMPLE, n)\n",
    "    rng = np.random.RandomState(RANDOM_SEED)\n",
    "    idx_sub = rng.choice(n, size=n_sub, replace=False)\n",
    "    X_sub = X[idx_sub, :]\n",
    "    Z = linkage(X_sub, method=\"ward\", metric=\"euclidean\")\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    dendrogram(Z, no_labels=True, color_threshold=CUT_HEIGHT, truncate_mode=\"lastp\", p=30)\n",
    "    plt.axhline(CUT_HEIGHT, ls=\"--\", color=\"tab:blue\", alpha=0.7)\n",
    "    plt.title(\"HAC (Ward) on Composite CAI — sample (cross-sectional)\")\n",
    "    plt.xlabel(\"Merged clusters (truncated)\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / \"hac_dendrogram_sample.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # 8) Histogram plot of K-means clusters with centroid markers\n",
    "    plt.figure(figsize=(7.6, 4.6))\n",
    "    mask_low = (km_labels01 == 0)\n",
    "    mask_high = (km_labels01 == 1)\n",
    "    plt.hist(X[mask_low].ravel(), bins=HIST_BINS, alpha=0.7, label=\"Cluster: Low\")\n",
    "    plt.hist(X[mask_high].ravel(), bins=HIST_BINS, alpha=0.7, label=\"Cluster: High\")\n",
    "    # centroid markers\n",
    "    plt.axvline(centroid_low, ls=\"--\", alpha=0.9)\n",
    "    plt.axvline(centroid_high, ls=\"--\", alpha=0.9)\n",
    "    plt.title(\"Composite CAI — clusters via HAC→KMeans (cross-sectional)\")\n",
    "    plt.xlabel(\"CAI\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / \"kmeans_histogram.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # 9) Console summary\n",
    "    print(\"\\nSilhouette summary:\")\n",
    "    print(sil_table.to_string(index=False))\n",
    "    print(f\"\\nCentroids (KMeans): low={centroid_low:.4f}, high={centroid_high:.4f}\")\n",
    "    print(f\"Artifacts saved in: {OUTDIR.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
